---
title: About me
permalink: /about/
date: 2022-10-16 20:38:00
updated: 2024-03-26
---
# Shuai Shao (邵帅)
<html>
    <style>
        table, th, td{
            border: 0;
        }
    </style>
    <table>
        <tr>
            <td width="50%">
                <img src="/images/9K7A4275.JPG" width=100%>
            </td>
            <td width="50%">
                <p>
                Lead Researcher, ByteDance<br>
                Personal Email: shaoshuai [at] acm.org<br>
                <del>Work Email: shaoshuai [at] megvii.com</del><br>
                Work Email: shaoshuai.0516 [at] bytedance.com<br>
                <a href="https://scholar.google.com/citations?user=uL9iyKgAAAAJ">[Google Scholar]</a>
                <a href="/ShuaiShao_CV.pdf">[CV]</a>
                </p>
            </td>
        </tr>
    </table>
</html>

# Biography
Shuai Shao, currently serving as a Lead Researcher at Bytedance <del>AI Lab</del> Monetization GenAI, is mentored by [Dr. Zehuan Yuan](https://shallowyuan.github.io/).  His research endeavors are deeply rooted in the realms of **Multimodal Content Understanding** and **AI-Generated Content**. Shuai is particularly passionate about developing robust systems that are applicable in real-world scenarios.

Shuai hails from Changchun, China, and earned his Bachelor of Science degree from [Jilin University](http://www.jlu.edu.cn/) in 2017. Upon graduation, he embarked on his professional journey at Megvii Research, where he was fortunate to be mentored by [Dr. Gang Yu](http://www.skicyyu.org/) and under the supervision of [Dr. Jian Sun](https://scholar.google.com/citations?user=ALVSZAYAAAAJ).

Shuai has been competing in programming contests since his high school years. He earned a gold medal in the 2013 ACM-ICPC Asia Regional Contest and secured the 19th position in the 2014 ACM-ICPC World Finals. Subsequently, he served as the coach for Jilin University's ACM-ICPC team until his graduation.


# Recent News
- [Dec. 2023] One paper is accepted by AAAI 2024.
- [Apr. 2023] One paper is accepted by SIGIR 2023.
- [Feb. 2022] One paper is accepted by TIP.
- [Apr. 2019] We published a new dataset [Objects365](https://www.objects365.org/): A Large-scale, High-quality Dataset for Object Detection.
- [Mar. 2019] We are organizing a workshop, [Detection In the Wild Challenge Workshop 2019](https://www.objects365.org/workshop2019.html), in conjunction with CVPR 2019.
- [Dec. 2018] A micro documentary about me on JSTV (in Chinese). [Link](http://news.jstv.com/a/20181225/1545907806823.shtml)
- [May 2018] We published a new dataset [CrowdHuman](https://sshao0516.github.io/CrowdHuman/), a benchmark for detecting human in a crowd.

# Awards
- Top Winner of WIDER Face in the WIDER Challenge, 2018.
- Top Winner of Places Instance Segmentation in COCO + Places 2017 Challenges, 2017.
- 19th Place of The 2014 ACM-ICPC World Finals, 2014.
- Gold Medal (2nd Place) of The 2013 ACM-ICPC Asia Regional Contest, 2013.

# Professional Activities
- Reviewer of IJCV, TIP, CVPR, ICCV, ACM MM.
- Organizer of Detection In the Wild Challenge Workshop (DIW) at CVPR2019. 

# Publications
**Conference**
> [EVE: Efficient Vision-Language Pre-training with Masked Prediction and Modality-Aware MoE.](https://arxiv.org/pdf/2308.11971.pdf)
Junyi Chen, Guo Longteng, Jia Sun, **Shuai Shao**, Zehuan Yuan, Liang Lin, Dongyu Zhang.
*AAAI*, 2024.

> [MAMO: Fine-Grained Vision-Language Representations Learning with Masked Multimodal Modeling.](https://arxiv.org/pdf/2210.04183)
Zijia Zhao*, Longteng Guo*, Xingjian He, **Shuai Shao**, Zehuan Yuan, Jing Liu.
*SIGIR*, 2023.

> [Objects365: A large-scale, high-quality dataset for object detection.](https://openaccess.thecvf.com/content_ICCV_2019/papers/Shao_Objects365_A_Large-Scale_High-Quality_Dataset_for_Object_Detection_ICCV_2019_paper.pdf)
**Shuai Shao**\*, Zeming Li\*, Tianyuan Zhang\*, Chao Peng\*, Gang Yu, Xiangyu Zhang, Jing Li, Jian Sun.
*ICCV*, 2019.

> [Shape Robust Text Detection with Progressive Scale Expansion Network.](https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Shape_Robust_Text_Detection_With_Progressive_Scale_Expansion_Network_CVPR_2019_paper.pdf)
Wenhai Wang*, Enze Xie*, Xiang Li*, Wenbo Hou, Tong Lu, Gang Yu, **Shuai Shao**.
*CVPR*, 2019.

> [Scene Text Detection with Supervised Pyramid Context Network.](https://ojs.aaai.org/index.php/AAAI/article/download/4935/4808)
Enze Xie*, Yuhang Zang*, **Shuai Shao**, Gang Yu, Cong Yao, Guangyao Li.
*AAAI*, 2019.

> [Repulsion Loss: Detecting Pedestrians in a Crowd.](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Repulsion_Loss_Detecting_CVPR_2018_paper.pdf)
Xinlong Wang, Tete Xiao, Yuning Jiang, **Shuai Shao**, Jian Sun, Chunhua Shen.
*CVPR*, 2018.

**Journal**
> [Birds of a Feather Flock Together: Category-Divergence Guidance for Domain Adaptive Segmentation.](https://arxiv.org/pdf/2204.02111.pdf)
Bo Yuan, Danpei Zhao, **Shuai Shao**, Zehuan Yuan, Changhu Wang.
*IEEE Transactions on Image Processing*, 2022.

**Pre-print**
> [CrowdHuman: A Benchmark for Detecting Human in a Crowd.](https://arxiv.org/pdf/1805.00123)
**Shuai Shao***, Zijian Zhao*, Boxun Li, Tete Xiao, Gang Yu, Xiangyu Zhang, Jian Sun.
*arXiv preprint arXiv:1805.00123*, 2018.

> [Object detection via end-to-end integration of aspect ratio and context aware part-based models and fully convolutional networks.](https://arxiv.org/pdf/1612.00534)
Bo Li, Tianfu Wu, **Shuai Shao**, Lun Zhang, Rufeng Chu.
*arXiv preprint arXiv:1612.00534*, 2016.

*_indicates equal contribution._

# Links
Research Collaborators:
[Mr. Yuning Jiang](https://yuningjiang.github.io/) [Zeming Li (黎泽明)](https://www.zemingli.com/) [Lan-Zhe Guo (郭兰哲)](http://www.guolz.com/) [Tianyuan Zhang (张天远)](http://tianyuanzhang.com/) [Enze Xie (谢恩泽)](https://xieenze.github.io/) [Xinlong Wang (王鑫龙)](https://www.xloong.wang/) [Changhu Wang (王长虎)](https://changhu.wang/) [Longteng Guo (郭龙腾)](https://ltguo19.github.io/) [Changqian Yu (余昌黔)](https://www.changqianyu.me/) [Bo Yuan (苑博)](https://ybio.github.io/) [Yiping Bao](https://scholar.google.com/citations?user=EB9_W4kAAAAJ) [Feng Wang](https://scholar.google.com/citations?user=ob2gp1QAAAAJ) [Limeng Qiao](https://scholar.google.com/citations?user=3PFZAg0AAAAJ) [Junyi Chen](https://ssyze.cn/)